# app.py
# -*- coding: utf-8 -*-
import io
import os
import joblib
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import streamlit as st
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# XGBoost ë¡œë”
USE_XGB = True
XGB_IMPORT_ERROR = ""
try:
    from xgboost import XGBRegressor
except Exception as e:
    USE_XGB = False
    XGB_IMPORT_ERROR = str(e)

DEFAULT_PATH = "ì„œìš¸ì‹œ_ì•„íŒŒíŠ¸_ì „ì›”ì„¸_ìš”ì•½.csv"  # [ì‹œêµ°êµ¬, í‰ìˆ˜, ì›”ì„¸ê¸ˆ(ë§Œì›), ê±´ì¶•ë…„ë„]

st.set_page_config(page_title="í‰ìˆ˜â†’ì›”ì„¸ ì˜ˆì¸¡ (XGBoost)", layout="wide")
st.title("ğŸ¢ ì„œìš¸ ì•„íŒŒíŠ¸ í‰ìˆ˜ â†’ ì›”ì„¸ ì˜ˆì¸¡ (XGBoost)")

with st.sidebar:
    st.header("ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°")
    uploaded = st.file_uploader("CSV ì—…ë¡œë“œ (ì˜ˆ: ì„œìš¸ì‹œ_ì•„íŒŒíŠ¸_ì „ì›”ì„¸_ìš”ì•½.csv)", type=["csv"])
    use_default = st.checkbox("ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©", value=not uploaded, help=f"í˜„ì¬ í´ë”ì˜ '{DEFAULT_PATH}' ì‚¬ìš©")

    st.markdown("---")
    st.subheader("ì „ì²˜ë¦¬ ì˜µì…˜")
    drop_zero = st.checkbox("ì „ì„¸(ì›”ì„¸=0) ì œê±°", value=True)
    trim_outliers = st.checkbox("ì´ìƒì¹˜ íŠ¸ë¦¬ë°(IQR ìƒë‹¨ 1.5)", value=True)
    min_pyeong, max_pyeong = st.slider("í‰ìˆ˜ ë²”ìœ„ í•„í„°", 3.0, 120.0, (3.0, 100.0), 0.5)
    test_size = st.slider("í…ŒìŠ¤íŠ¸ì…‹ ë¹„ìœ¨", 0.05, 0.4, 0.2, 0.05)

    st.markdown("---")
    st.subheader("íŠ¹ì§•(Feature) ì„ íƒ")
    use_only_pyeong = st.checkbox("í‰ìˆ˜ë§Œ ì‚¬ìš© (ê¸°ë³¸)", value=True)
    use_year = st.checkbox("ê±´ì¶•ë…„ë„ í¬í•¨", value=False, disabled=use_only_pyeong)
    use_region = st.checkbox("ì‹œêµ°êµ¬ í¬í•¨(ì›-í•« ì¸ì½”ë”©)", value=False, disabled=use_only_pyeong)

    st.markdown("---")
    st.subheader("ëª¨ë¸ ì„¤ì •")
    n_estimators = st.slider("n_estimators", 50, 600, 300, 50)
    max_depth = st.slider("max_depth", 2, 12, 4, 1)
    learning_rate = st.select_slider("learning_rate", options=[0.03, 0.05, 0.08, 0.1, 0.2], value=0.08)
    reg_lambda = st.select_slider("reg_lambda", options=[0.0, 0.5, 1.0, 2.0, 5.0], value=1.0)
    train_btn = st.button("ğŸ” ëª¨ë¸ í•™ìŠµ / ì¬í•™ìŠµ")

def read_csv_safely(file_or_path):
    tried = []
    for enc in ["utf-8-sig", "cp949"]:
        try:
            return pd.read_csv(file_or_path, encoding=enc)
        except Exception as e:
            tried.append(f"{enc}: {e}")
            continue
    return pd.read_csv(file_or_path)

if uploaded is not None:
    df_raw = read_csv_safely(uploaded)
elif use_default and os.path.exists(DEFAULT_PATH):
    df_raw = read_csv_safely(DEFAULT_PATH)
else:
    st.warning("CSVë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ 'ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©'ì„ ì²´í¬í•´ ì£¼ì„¸ìš”.")
    st.stop()

expected = ["ì‹œêµ°êµ¬", "í‰ìˆ˜", "ì›”ì„¸ê¸ˆ(ë§Œì›)", "ê±´ì¶•ë…„ë„"]
missing = [c for c in expected if c not in df_raw.columns]
if missing:
    st.error(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing}\nCSVì— ë‹¤ìŒ ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤: {expected}")
    st.stop()

df = df_raw.copy()
df["í‰ìˆ˜"] = pd.to_numeric(df["í‰ìˆ˜"], errors="coerce")
df["ì›”ì„¸ê¸ˆ(ë§Œì›)"] = pd.to_numeric(df["ì›”ì„¸ê¸ˆ(ë§Œì›)"], errors="coerce")
df["ê±´ì¶•ë…„ë„"] = pd.to_numeric(df["ê±´ì¶•ë…„ë„"], errors="coerce")

df = df[(df["í‰ìˆ˜"] >= min_pyeong) & (df["í‰ìˆ˜"] <= max_pyeong)]
df = df.dropna(subset=["í‰ìˆ˜", "ì›”ì„¸ê¸ˆ(ë§Œì›)"])
if drop_zero:
    df = df[df["ì›”ì„¸ê¸ˆ(ë§Œì›)"] > 0]
if trim_outliers and len(df) > 0:
    q1, q3 = df["ì›”ì„¸ê¸ˆ(ë§Œì›)"].quantile([0.25, 0.75])
    iqr = q3 - q1
    upper = q3 + 1.5 * iqr
    df = df[df["ì›”ì„¸ê¸ˆ(ë§Œì›)"] <= upper]

st.success(f"ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(df):,}ê±´")
with st.expander("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
    st.dataframe(df.head(20))

feature_cols = ["í‰ìˆ˜"]
if not use_only_pyeong:
    if use_year:
        feature_cols.append("ê±´ì¶•ë…„ë„")
    if use_region:
        feature_cols.append("ì‹œêµ°êµ¬")

X_df = df[feature_cols].copy()
y = df["ì›”ì„¸ê¸ˆ(ë§Œì›)"].values

numeric_features = [c for c in feature_cols if c != "ì‹œêµ°êµ¬"]
categorical_features = ["ì‹œêµ°êµ¬"] if "ì‹œêµ°êµ¬" in feature_cols else []

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
preprocess = ColumnTransformer(
    transformers=[
        ("num", "passthrough", numeric_features),
        ("cat", OneHotEncoder(handle_unknown="ignore"), categorical_features),
    ],
    remainder="drop",
)

if not USE_XGB:
    st.error("xgboostê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. í„°ë¯¸ë„ì—ì„œ `pip install xgboost` í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
    st.stop()

from xgboost import XGBRegressor
reg = XGBRegressor(
    n_estimators=int(n_estimators),
    max_depth=int(max_depth),
    learning_rate=float(learning_rate),
    subsample=0.9,
    colsample_bytree=1.0,
    reg_lambda=float(reg_lambda),
    random_state=42,
    n_jobs=1,
    tree_method="hist",
    objective="reg:squarederror",
)

model = Pipeline(steps=[("prep", preprocess), ("reg", reg)])

if train_btn or "fitted_" not in st.session_state:
    if len(df) < 10:
        st.warning("ë°ì´í„°ê°€ ë„ˆë¬´ ì ì–´ í•™ìŠµì´ ì–´ë ¤ì›Œìš”. ìµœì†Œ 10ê±´ ì´ìƒ ê¶Œì¥í•©ë‹ˆë‹¤.")
    X_train, X_test, y_train, y_test = train_test_split(
        X_df, y, test_size=float(test_size), random_state=42
    )
    model.fit(X_train, y_train)
    st.session_state["fitted_"] = True
    st.session_state["model"] = model
    st.session_state["X_test"] = X_test
    st.session_state["y_test"] = y_test
    st.toast("ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!", icon="âœ…")

if "model" not in st.session_state:
    st.stop()

model = st.session_state["model"]
X_test = st.session_state["X_test"]
y_test = st.session_state["y_test"]
pred = model.predict(X_test)

mae = mean_absolute_error(y_test, pred)
rmse = mean_squared_error(y_test, pred, squared=False)
r2 = r2_score(y_test, pred)

col1, col2, col3 = st.columns(3)
col1.metric("MAE (ë§Œì›)", f"{mae:.2f}")
col2.metric("RMSE (ë§Œì›)", f"{rmse:.2f}")
col3.metric("RÂ²", f"{r2:.3f}")

st.subheader("ì‹¤ì œ vs ì˜ˆì¸¡ (í…ŒìŠ¤íŠ¸ì…‹)")
fig = plt.figure()
plt.scatter(y_test, pred, alpha=0.6)
plt.xlabel("ì‹¤ì œ ì›”ì„¸(ë§Œì›)")
plt.ylabel("ì˜ˆì¸¡ ì›”ì„¸(ë§Œì›)")
plt.title("ì‹¤ì œ vs ì˜ˆì¸¡")
st.pyplot(fig)

st.markdown("---")
st.header("ğŸ”® ì›”ì„¸ ì˜ˆì¸¡")

inp_p = st.slider("í‰ìˆ˜", float(df["í‰ìˆ˜"].min()), float(df["í‰ìˆ˜"].max()), float(np.median(df["í‰ìˆ˜"])), 0.5)

extra = {}
if "ê±´ì¶•ë…„ë„" in feature_cols:
    yr_min = int(np.nan_to_num(df["ê±´ì¶•ë…„ë„"].min(), nan=1990))
    yr_max = int(np.nan_to_num(df["ê±´ì¶•ë…„ë„"].max(), nan=2025))
    extra["ê±´ì¶•ë…„ë„"] = st.number_input("ê±´ì¶•ë…„ë„", min_value=1900, max_value=2100, value=min(max(yr_min, 1990), yr_max))

if "ì‹œêµ°êµ¬" in feature_cols:
    regions = sorted(df["ì‹œêµ°êµ¬"].dropna().unique().tolist())
    extra["ì‹œêµ°êµ¬"] = st.selectbox("ì‹œêµ°êµ¬", options=regions, index=0 if regions else None)

def build_input_row(pyeong: float, extras: dict) -> pd.DataFrame:
    row = {"í‰ìˆ˜": float(pyeong)}
    for k in ["ê±´ì¶•ë…„ë„", "ì‹œêµ°êµ¬"]:
        if k in feature_cols:
            if k == "ê±´ì¶•ë…„ë„":
                row[k] = extras.get(k, int(np.nan_to_num(df["ê±´ì¶•ë…„ë„"].median(), nan=2005)))
            if k == "ì‹œêµ°êµ¬":
                row[k] = extras.get(k, df["ì‹œêµ°êµ¬"].mode().iloc[0] if not df["ì‹œêµ°êµ¬"].empty else "")
    return pd.DataFrame([row], columns=feature_cols)

if st.button("ì˜ˆì¸¡ ì‹¤í–‰"):
    X_row = build_input_row(inp_p, extra)
    y_hat = float(model.predict(X_row)[0])
    st.success(f"ì˜ˆì¸¡ ì›”ì„¸: **{y_hat:.1f} ë§Œì›**")

st.markdown("---")
st.subheader("ëª¨ë¸ ë‚´ë³´ë‚´ê¸°")
bytes_buf = io.BytesIO()
joblib.dump(model, bytes_buf)
st.download_button("ğŸ’¾ í•™ìŠµ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (.pkl)", data=bytes_buf.getvalue(), file_name="rent_xgb_model.pkl")

st.caption("Tip: í‰ìˆ˜ í•˜ë‚˜ë§Œìœ¼ë¡œëŠ” ì§€ì—­Â·ì—°ì‹ íš¨ê³¼ë¥¼ ë°˜ì˜í•˜ê¸° ì–´ë ¤ì›Œ RÂ²ê°€ ë‚®ì„ ìˆ˜ ìˆì–´ìš”. "
           "ì‚¬ì´ë“œë°”ì—ì„œ 'ê±´ì¶•ë…„ë„', 'ì‹œêµ°êµ¬'ë¥¼ ì¶”ê°€í•˜ë©´ ì„±ëŠ¥ì´ ê°œì„ ë©ë‹ˆë‹¤.")
